#config file for prediction

#----------------------------------------------------------------------------------------------
#global
#----------------------------------------------------------------------------------------------
#filename of rawdata, rawdata in format [i_img, x, y, ch=0]
global-filename_rawdata=rawdata_downscaled.h5   
#filename of dataset for rawdata
global-datasetname_rawdata=data
#Exist an orientation with defined back and front? if true: global-arrow_orientation if not 
#(i.e. there exist an orientation only via an axis) comment it out 
#global-arrow_orientation
#number of rotations of probmap predictions of autocontext and scoremaps, and center for rotation
global-n_rot=4
global-x_center=106
global-y_center=93


#----------------------------------------------------------------------------------------------
#preprocessing
#----------------------------------------------------------------------------------------------
    
#if true only img with idx between idx_begin and idx_end are chosen, if false comment out
preprocessing-time_interval
#start idx for cropping in time
preprocessing-idx_begin=0
#end idx for cropping in time
#800+4*200
preprocessing-idx_end=49
#selecting every i th image for tracking 
preprocessing-every_i_img_rawdata=1 
#if true spatial cropping according to [x_start,x_end) [y_start,y_end), if false comment out
preprocessing-spatial_cropping
#boundaries for spatial cropping
preprocessing-x_start=19
preprocessing-x_end=232
preprocessing-y_start=1000
preprocessing-y_end=1186

#----------------------------------------------------------------------------------------------
#Autocontext
#----------------------------------------------------------------------------------------------
#number of different classes for using autocontext, must be equal in config_train.ini
autocontext-n_classes=4
#number of stage for autocontext, must be equal in config_train.ini
autocontext-n_stages=2 
#merge auxiliary classes to one class
#new merged classes: i_merged_class_j_old_class: ith merged class comprises jth old 
#class denoted index
#1<=i<=4: maximal 4 merged classes can exist 
#1<=j<=4: up to 4 classes can be merged
autocontext-1_merged_class_1_old_class=1
#autocontext-1_merged_class_2_old_class=2
autocontext-2_merged_class_1_old_class=2
#save in addition probmaps before merging in folder Autocontext/output/pred/
#autocontext-save_many_class_probmaps
#save hard segmentation for insight, if false: comment it out, in folder DPM/samples/pred/hardseg
#autocontext-save_hard_seg


#----------------------------------------------------------------------------------------------
#DPM (Deformable Part Model)
#----------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------
#MHT (MultiHypothesesTracking)
#----------------------------------------------------------------------------------------------
#should a Laplacian of Gaussian applied on scoremaps before generating hypotheses
#radius for finding hypotheses with highest score as initialization in first and last frame
#unit: in pxl in cropped rawdata
mht-radius_ini=15.
#relative weights for energy compontents
mht-weight_trans_move=1.
mht-weight_trans_angle=3.
mht-weight_det=1.
#mht-use_LoG
#sigma of LoG when used
mht-sigma_LoG=1.
#energy gap tolerated by solving ILP
mht-energy_gap_graphical_model=0.01
#threshold for local maxima beeing hypothesis
mht-threshold_abs=2.
#maximal possible transition distance
#unit: in pxl in cropped rawdata
mht-max_move_per_frame=15.
#hypotheses within one frame with a smaller distance than this conflict radius are never used for two different tracks
#unit: in pxl in cropped rawdata
mht-conflict_radius=5..
#angle weights (max 16 weights, should be global-n_rot/2+1): they are transformed later on into a list and are the energies for the change in orientation  in transition classifier
mht-angle_weight_1=0.
mht-angle_weight_2=20.
mht-angle_weight_3=135.
#mht-angle_weight_4=500.
#mht-angle_weight_5=500.



